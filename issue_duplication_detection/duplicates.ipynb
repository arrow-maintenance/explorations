{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8e91e93-bfa2-448f-952c-0ff089d15647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import itertools\n",
    "import gzip\n",
    "import json\n",
    "from qdrant_client import models, QdrantClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4a5eec7-2669-41f3-aa3c-40551d8c1950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46076"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data and convert to records format\n",
    "with gzip.open(\"../test_data/issues_min.json.gz\", \"rt\", encoding=\"utf-8\") as f:\n",
    "    df = json.load(f)\n",
    "  \n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "data = df.to_dict('records')\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efc52e08-3478-4cb8-9272-eef6d06ea362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model to create embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(just_titles, convert_to_tensor=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd00cde8-0981-484f-9d1a-aa028b49caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up index to search\n",
    "emb_np = embeddings.cpu().numpy().astype('float32')\n",
    "faiss.normalize_L2(emb_np)\n",
    "\n",
    "index = faiss.IndexFlatIP(emb_np.shape[1])  # Inner product = cosine if normalized\n",
    "index.add(emb_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd209d0c-cece-43f7-b6ca-d0ef1d0f819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "238db62f-61a3-44dc-b985-22ebfdd93029",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbours_per_issue = 2\n",
    "similarity_cutoff = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "783cd9af-79a3-4cc2-be22-f35b863ad829",
   "metadata": {},
   "outputs": [],
   "source": [
    "D, I = index.search(emb_np, neighbours_per_issue)\n",
    "\n",
    "duplicates = []\n",
    "\n",
    "for idx, (neighbors, sims) in enumerate(zip(I, D)):\n",
    "    for j, sim in zip(neighbors[1:], sims[1:]):  # skip self\n",
    "        if sim > similarity_cutoff:\n",
    "            duplicates.append((idx, j, sim))\n",
    "\n",
    "duplicates = sorted(duplicates, key=lambda x: -x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5082bea-b58a-4855-a8f5-7f1dfb509e43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2561427d-a271-477f-b9ba-414fa71f9f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen = set()\n",
    "html_snippets = []\n",
    "\n",
    "for idx1, idx2, sim in duplicates:\n",
    "    # Skip if either issue already used\n",
    "    if idx1 in seen or idx2 in seen:\n",
    "        continue\n",
    "\n",
    "    issue1 = non_prs[int(idx1)]\n",
    "    issue2 = non_prs[int(idx2)]\n",
    "\n",
    "    block = f\"\"\"\n",
    "<br>\n",
    "<b>Issue:</b> <a target=\"blank\" href=\"{issue1['url']}\">{issue1['title']}</a><br>\n",
    "<b>Duplicate:</b> <a target=\"blank\" href=\"{issue2['url']}\">{issue2['title']}</a><br>\n",
    "<b>Score:</b> {sim:.3f}<br>\n",
    "<br>\n",
    "\"\"\"\n",
    "    html_snippets.append(block)\n",
    "\n",
    "    # Mark both as seen so we don’t include them again\n",
    "    seen.add(idx1)\n",
    "    seen.add(idx2)\n",
    "\n",
    "html_output = \"\\n\".join(html_snippets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "153ecfa0-93ae-4bbb-bd8d-618ff81f481d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/31850\">[C++] Automatically convert from Substrait options to Arrow options object</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/31850\">[C++] Automatically convert from Substrait options to Arrow options object</a><br>\n",
       "<b>Score:</b> 1.000<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30389\">[R] Implement bindings for stringr::str_glue_data</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30388\">[R] Implement bindings for stringr::str_glue</a><br>\n",
       "<b>Score:</b> 0.967<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/40018\">[CI][Archery] Archery linking should also check for undefined symbols</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/40966\">[CI][Archery] Archery linking should also check for undefined symbols Windows</a><br>\n",
       "<b>Score:</b> 0.967<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/43662\">[R] Add binding to `stringr::str_replace_na()`</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30399\">[R] Implement bindings for stringr::str_replace_na</a><br>\n",
       "<b>Score:</b> 0.957<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/40264\">[Python] Add `pyarrow.dataset.dataset` doesn't accept `RecordBatchReader`</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/38012\">[Python] pyarrow.dataset.dataset does not accept RecordBatchReader as source</a><br>\n",
       "<b>Score:</b> 0.956<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/18957\">[R] Implement bindings for stringr::str_split_n</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30364\">[R] Implement bindings for stringr::str_split_fixed</a><br>\n",
       "<b>Score:</b> 0.956<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/36864\">[R] Update `write_csv_arrow()` implementation to match `readr::write_csv()`</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30427\">[R] Update write_csv_arrow() to support all args of readr::write_csv()</a><br>\n",
       "<b>Score:</b> 0.948<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/31973\">[R] open_dataset fails to open single compressed csv</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30575\">[R] open_dataset() on csv files lacks support for compressed files</a><br>\n",
       "<b>Score:</b> 0.941<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/42949\">[C++][Parquet] Expose an API that allows direct writing of RLE information for rep/def levels when writing parquet files</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/42377\">[C++][Parquet] Expose an API that surface RLE information for rep/def levels when reading parquet files</a><br>\n",
       "<b>Score:</b> 0.940<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/45682\">[Python] Failing to create array from null scalar</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/40319\">[Python] Creating an array from a null list scalar fails</a><br>\n",
       "<b>Score:</b> 0.940<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/29014\">[C++] Implement hash_aggregate kernels (umbrella issue)</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/28986\">[C++] Implement hash_aggregate mode kernel</a><br>\n",
       "<b>Score:</b> 0.940<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30472\">[R] Implement lubridate's interval type and lubridate functions as.interval(), interval() and %--%</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30471\">[R] Implement lubridate interval functions</a><br>\n",
       "<b>Score:</b> 0.936<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30889\">[Python] Change the default write partitioning flavor to hive</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30888\">[Python] Change the default read partitioning flavor to hive</a><br>\n",
       "<b>Score:</b> 0.934<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/33055\">pyarrow.json.read_json ignores nullable=True on fields with non-nullable subfields in explicit_schema parse_options</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/31957\">[Python] pyarrow.json.read_json ignores nullable=False in explicit_schema parse_options</a><br>\n",
       "<b>Score:</b> 0.934<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/39432\">[C++][Parquet] Add support for writing DictionaryArrays with nested value types to Parquet</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30080\">[C++][Parquet] Writing DictionaryArrays with ExtensionType to Parquet</a><br>\n",
       "<b>Score:</b> 0.931<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/32752\">Build python lib failed for ARMv8</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/20352\">[Python] build python lib failed on both X86 and ARMv8</a><br>\n",
       "<b>Score:</b> 0.929<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/45947\">GH-45937: [C++][Parquet] Variant encoding</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/45946\">GH-45937: [C++][Parquet] Variant decoding</a><br>\n",
       "<b>Score:</b> 0.927<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/32438\">[C++] HadoopFileSystem open_append_stream throwing an error if file does not exists</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30449\">[C++] HadoopFileSystem.open_append_stream not implemented correctly</a><br>\n",
       "<b>Score:</b> 0.926<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/45504\">Memory Leak with Pandas read_parquet using pyarrow engine</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/44472\">Memory Leak when Importing Parquet File with PyArrow Engine in Pandas</a><br>\n",
       "<b>Score:</b> 0.925<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/21290\">[C++][ORC] Enable copy free conversion for Composite type</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/21289\">[C++][ORC] Enable copy free conversion for primitive types</a><br>\n",
       "<b>Score:</b> 0.925<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/46461\">[C++] Review `arrow/json` headers for internal APIs</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/46459\">[C++] Review `arrow/util` headers for internal APIs</a><br>\n",
       "<b>Score:</b> 0.925<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/44881\">[Python][C++] Casting nested list array with null structs results in invalid array</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/43838\">[Python][C++] Casting a list of struct array with null field results in invalid result</a><br>\n",
       "<b>Score:</b> 0.924<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/39194\">[Python] pa.Table.to_pandas(zero_copy_only=True) never succeeds</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/38644\">[Python] Non zero-copy of pa.table.to_pandas() for simple case</a><br>\n",
       "<b>Score:</b> 0.921<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/29979\">[R] Implement dplyr::bind_cols()</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/29978\">[R] Implement dplyr::bind_rows()</a><br>\n",
       "<b>Score:</b> 0.920<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/40263\">[Python] Add FlightSqlServer bindings</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/40168\">[Python] Add FlightSql client bindings</a><br>\n",
       "<b>Score:</b> 0.920<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/18963\">[R] Implement bindings for stringr::str_sort</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30395\">[R] Implement bindings for stringr::str_order</a><br>\n",
       "<b>Score:</b> 0.920<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/20376\">[C++] Substrait to Arrow Aggregate doesn't take the provided Output Type for aggregates</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/32524\">[C++] Calculate output type from aggregate to convert arrow aggregate to substrait</a><br>\n",
       "<b>Score:</b> 0.915<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/20413\">[C++][Gandiva] Add token and grammar rules for functions</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/32958\">[C++][Gandiva] Add token and grammar rules for literals and fields</a><br>\n",
       "<b>Score:</b> 0.911<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/25797\">[Python] Reading Parquet file crashes on windows - python3.8</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/24569\">[Python][Parquet] Crash on parquet.read_table on windows python 3.82</a><br>\n",
       "<b>Score:</b> 0.910<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/40965\">[CI][Archery] Archery linking should also check for undefined symbols macOS</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/40964\">[CI][Archery] Archery linking should also check for undefined symbols Linux</a><br>\n",
       "<b>Score:</b> 0.910<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/38032\">[R] read_parquet performs to slow</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/13720\">read_parquet super slow</a><br>\n",
       "<b>Score:</b> 0.908<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/23712\">[C++] Remove compute pointer aliases</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/23709\">[C++] Remove pointer aliases </a><br>\n",
       "<b>Score:</b> 0.907<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/32611\">implement the round-shift for fixed size data type </a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/32610\">[C++] Implement the round-shift for fixed size data type </a><br>\n",
       "<b>Score:</b> 0.904<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/19923\">[C++][Parquet] Support Decimal from Int32/Int64 in StatisticsAsScalars</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/27852\">[C++][Parquet] StatisticsAsScalars doesn't support Decimal conversion for int primitives</a><br>\n",
       "<b>Score:</b> 0.904<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/39296\">[C++][Python] DLPack implementation for Arrow Arrays with CudaBuffers</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/39295\">[C++][Python] DLPack implementation for Arrow Arrays (consuming)</a><br>\n",
       "<b>Score:</b> 0.904<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/25507\">[C++/Python] Add option to Take kernel to interpret negative indices as NULL</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/25506\">[C++/Python] Add option to Take kernel to interpret negative indices as indexing from the right</a><br>\n",
       "<b>Score:</b> 0.903<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/34491\">[Python] Add pyarrow.TableGroupBy() subtables</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/14898\">[Python] Add pyarrow.TableGroupBy.groups method</a><br>\n",
       "<b>Score:</b> 0.902<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/42037\">[python] chunked_array from ChunkedArray</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/34495\">[Python] Make `ChunkedArray` & `Array` iterable</a><br>\n",
       "<b>Score:</b> 0.901<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30401\">[R] Implement bindings for stringr::str_trunc</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30397\">[R] Implement bindings for stringr::str_conv</a><br>\n",
       "<b>Score:</b> 0.901<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/14686\">[Python] OSError: Unable to load libjvm: /usr/java/latest//lib/amd64/server/libjvm.so</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/12743\">[Python]OSError: Unable to load libjvm. when used in windows</a><br>\n",
       "<b>Score:</b> 0.898<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30724\">parquet StreamWriter TIME support</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30709\">parquet StreamWriter nanosecond timestamp support</a><br>\n",
       "<b>Score:</b> 0.896<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/32185\">[C++] Add Roundtrip Support to Plans</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/31862\">[C++] Add roundtrip support to plans + relations</a><br>\n",
       "<b>Score:</b> 0.892<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30394\">[R] Implement bindings for stringr::str_equal</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30398\">[R] Implement bindings for stringr::str_like</a><br>\n",
       "<b>Score:</b> 0.891<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/45139\">[R] slice_sample does not sample randomly</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/38638\">[R] slice_sample returns 0 rows</a><br>\n",
       "<b>Score:</b> 0.890<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/45385\">Excessive memory usage in creating a pyarrow Table from pandas</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/36101\">Memory leak using pyarrow.Table and to_pandas method</a><br>\n",
       "<b>Score:</b> 0.890<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/45640\">[Python] - Schema inference from pandas reorders struct fields</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/34250\">[Python] Schema inference reorders fields in nested structs</a><br>\n",
       "<b>Score:</b> 0.890<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/31018\">[C++][Parquet] Field-level metadata are not supported? (ColumnMetadata.key_value_metadata)</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/42757\">[C++][Parquet] Expose key_value_metadata in parquet::ColumnChunkMetaData</a><br>\n",
       "<b>Score:</b> 0.889<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/43530\">Add support to write Parquet with bloom filters</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/40548\">[C++][Parquet] Add support for writing bloom filter to a Parquet file</a><br>\n",
       "<b>Score:</b> 0.888<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/40073\">[R][Python] Unable to load pyarrow package through reticulate in R on windows</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/29005\">[R][Python] DLL ImportError loading pyarrow with reticulate</a><br>\n",
       "<b>Score:</b> 0.887<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/39198\">[Python][R][Docs] Update the \"Integrating PyArrow with R\" documentation section to not use `_import_from_c`/`_export_to_c`</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/44872\">[Python][Java][Docs] Update the \"Integrating PyArrow with Java\" documentation section to not use `_import_from_c`/`_export_to_c`</a><br>\n",
       "<b>Score:</b> 0.886<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/39182\">[C++] Deprecate Scalar::CastTo</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/25124\">[C++] Deprecate or remove Scalar::Parse and Scalar::CastTo</a><br>\n",
       "<b>Score:</b> 0.884<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/37855\">[R] Copy_files not copying specific file</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/35992\">[R] `copy_files()` fails silently</a><br>\n",
       "<b>Score:</b> 0.884<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/38490\">[C++][Compute] Support ChunkedArray sorting for dictionary type</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/36772\">[C++] Dictionary sorting not implemented on chunked array and table</a><br>\n",
       "<b>Score:</b> 0.881<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30508\">[C++]Memory leak while reading parquet file</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/26606\">[C++][parquet][hadoop]memory leak when read parquet file from hadoop</a><br>\n",
       "<b>Score:</b> 0.881<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/18964\">[R] Implement bindings for stringr::invert_match</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30362\">[R] Implement bindings for stringr::str_match and stringr::str_match_all</a><br>\n",
       "<b>Score:</b> 0.880<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/34383\">[R][Docs] Improve docs for read_csv_arrow's usage</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/33370\">[R] read_csv_arrow() Improvements</a><br>\n",
       "<b>Score:</b> 0.880<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30367\">[R] Implement bindings for stringr's combining strings functions</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30343\">[R] Implement bindings for stringr's pattern matching functions</a><br>\n",
       "<b>Score:</b> 0.877<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/40063\">[C++][Python] Row-major conversion of Table/RecordBatch to Arrow Tensor</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/40062\">[C++][Python] Conversion of Table to Arrow Tensor</a><br>\n",
       "<b>Score:</b> 0.877<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/43558\">[Python] Segfault when turning parquet dataset into table with a filter</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/37747\">[Python][Parquet] Writing a parquet table fails with `segfault`</a><br>\n",
       "<b>Score:</b> 0.877<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/43126\">[Python] Not able to import pyarrow.parquet</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/32603\">[Python] Parquet should be listed in PyArrow's get_libraries() function</a><br>\n",
       "<b>Score:</b> 0.870<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/44317\">[Python] pyarrow.Table.take() is much slower when reading a parquet with read_table instead of from_batches since pyarrow 8.0.0</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/34566\">[Python] pyarrow.parquet.read_table is very long for the first read call</a><br>\n",
       "<b>Score:</b> 0.870<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/40122\">[Python] Incorrect conversion from datetime.datetime and datetime.time objects with non-UTC timezones</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/16806\">[Python] conversion from datetime objects with mixed timezones should normalize to UTC</a><br>\n",
       "<b>Score:</b> 0.869<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/41809\">[C++] Add Compute Kernel for Casting from struct to string</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/41668\">[C++] Add Compute Kernel for Casting from list-like to string</a><br>\n",
       "<b>Score:</b> 0.868<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/45798\">[C++] Add extension directory to Meson</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/45778\">[C++] Add subdirectories to Meson Configuration</a><br>\n",
       "<b>Score:</b> 0.868<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/31971\">[C++][Python] strptime fails to parse with %p on Windows</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/31816\">[C++][R] strptime fails to parse with %b or %B on Windows</a><br>\n",
       "<b>Score:</b> 0.868<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/32184\">[C++] Adding Aggregate Relation ToProto</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/32183\">[C++] Adding Join Relation ToProto</a><br>\n",
       "<b>Score:</b> 0.864<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/40636\">[Parquet] Make default fallback encoding choice smarter</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/38441\">[Parquet] Encoding configuration should be easier and more automated</a><br>\n",
       "<b>Score:</b> 0.863<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/43198\">[C++][Gandiva] InExpression for Decimal128 segfaults.</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/39784\">[C++][Gandiva] Segfault when in_expr of decimal type cached and crash</a><br>\n",
       "<b>Score:</b> 0.863<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/26783\">[C++] CSV date custom parser</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/26224\">[C++] Use timestamp parsers for date32() CSV parsing</a><br>\n",
       "<b>Score:</b> 0.862<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/31745\">[Docs] How to run CI builds locally - Linux</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/31744\">[Docs] How to run CI builds locally - Windows</a><br>\n",
       "<b>Score:</b> 0.862<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/38178\">[R] open_dataset - format is unclear</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/33486\">[R] Issues with open_dataset()</a><br>\n",
       "<b>Score:</b> 0.861<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/40845\">[C++][Parquet] Investigate optimizing level decoding</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/24663\">[C++][Parquet] Add benchmarks for rep/def level decoding at multiple levels</a><br>\n",
       "<b>Score:</b> 0.861<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/46138\">[Python] Support pyarrow.Table.cast with CastOptions</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/35408\">[Python] cast doesn't work for structure in pyarrow</a><br>\n",
       "<b>Score:</b> 0.860<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30387\">[R] Implement bindings for stringr::str_flatten</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30392\">[R] Implement bindings for stringr::str_wrap</a><br>\n",
       "<b>Score:</b> 0.860<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/38792\">[C++] [Gandiva] Optimize Gandiva Cache</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/27926\">[C++][Gandiva] Implement new cache for Gandiva focused on a build time policy</a><br>\n",
       "<b>Score:</b> 0.859<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/35697\">[C++][Parquet] NotImplemented: Lists with non-zero length null components are not supported</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/35692\">[C++][Parquet] Null fixed-length lists cannot be read from parquet file</a><br>\n",
       "<b>Score:</b> 0.859<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30400\">[R] Implement bindings for stringr::`str_sub<-`</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/30365\">[R] Implement bindings for stringr::str_subset</a><br>\n",
       "<b>Score:</b> 0.859<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/38707\">[C++] Parquet RecordReader Skip performance is bad</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/28785\">[C++][Parquet] StreamReader.SkipColumns slow</a><br>\n",
       "<b>Score:</b> 0.858<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/46724\">[C++][Parquet] Bad-cast in handling statistics</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/34139\">[C++][Parquet] Ignore corrupted or invalid statistics </a><br>\n",
       "<b>Score:</b> 0.856<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/32506\">[C++][R] Strptime should detect invalid formats</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/31254\">[R] [C++] Should strptime support a partial format?</a><br>\n",
       "<b>Score:</b> 0.856<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/23592\">[Python] High memory usage writing pyarrow.Table with large strings to parquet</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/32670\">pyarrow may use a lot of memory to load a dataframe from parquet</a><br>\n",
       "<b>Score:</b> 0.854<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/18560\">[Gandiva][C++]Support regex mode options in LIKE</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/23503\">[C++][Gandiva] Implement regexp_matches, regexp_like functions</a><br>\n",
       "<b>Score:</b> 0.854<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/13949\">[java] reading multiple parquet files takes unresonable amount of memory</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/44599\">[Parquet] >2GiB Memory Leak on reading single parquet metadata file</a><br>\n",
       "<b>Score:</b> 0.852<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/34683\">[Python] ArrowInvalid error when trying to read list of s3 paths in pyarrow.dataset</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/31812\">[Python] pyarrow dataset API fails to read s3 directory</a><br>\n",
       "<b>Score:</b> 0.851<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/45806\">[C++] Statistics Schema Implementation</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/45639\">[C++] implement Statistic Schema attribute in C++</a><br>\n",
       "<b>Score:</b> 0.851<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/35259\">[Python] Pyarrow table conversion from pandas fails for categorical fields with arrow dtypes</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/34239\">[Python] Conversion of pyArrow table to pandas fails with error: ArrowException: Unknown error: Wrapping Q� failed </a><br>\n",
       "<b>Score:</b> 0.851<br>\n",
       "<br>\n",
       "\n",
       "\n",
       "<br>\n",
       "<b>Issue:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/33042\">[C++] Implement arithmetic kernels on List(number)</a><br>\n",
       "<b>Duplicate:</b> <a target=\"blank\" href=\"https://github.com/apache/arrow/issues/28490\">[C++] Arithmetic kernels for numeric arrays</a><br>\n",
       "<b>Score:</b> 0.850<br>\n",
       "<br>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(html_output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
